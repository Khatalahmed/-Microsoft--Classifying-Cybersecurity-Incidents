{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7Aq_EPfnAb6",
        "outputId": "0d2f85b1-e9f6-4878-ae63-346f762e91ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Load Train Data\n",
        "train_data_path = \"/content/drive/My Drive/final_train1_data.csv\"\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "\n",
        "# Load Test Data\n",
        "test_data_path = \"/content/drive/My Drive/final_test_data.csv\"\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Display the first few rows\n",
        "print(\"✅ Train Data Loaded Successfully:\")\n",
        "print(train_data.head())\n",
        "\n",
        "print(\"✅ Test Data Loaded Successfully:\")\n",
        "print(test_data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad-o_aLvnWdy",
        "outputId": "dea5d4d4-5587-46cf-bf65-89e6330c15c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✅ Train Data Loaded Successfully:\n",
            "   AlertTitle  Category  IncidentGrade  EntityType  EvidenceRole  Url  \\\n",
            "0           4        17              1          26             0    0   \n",
            "1           4        16              2          26             0    0   \n",
            "2           4        17              0          14             0    0   \n",
            "3           3         8              0          20             1    0   \n",
            "4           4         2              2          26             0    0   \n",
            "\n",
            "   AccountName  DeviceName  CountryCode  State  ...  Hour_21  Hour_22  \\\n",
            "0            4           0            0      0  ...        0        0   \n",
            "1            4           0            0      0  ...        0        0   \n",
            "2            3           0            0      0  ...        0        0   \n",
            "3            3           0            0      0  ...        0        0   \n",
            "4            4           0            0      0  ...        0        0   \n",
            "\n",
            "   Hour_23  Hour_3  Hour_4  Hour_5  Hour_6  Hour_7  Hour_8  Hour_9  \n",
            "0        0       1       0       0       0       0       0       0  \n",
            "1        0       0       0       0       0       0       0       0  \n",
            "2        0       0       0       0       0       0       0       0  \n",
            "3        0       0       0       0       0       0       0       0  \n",
            "4        0       0       0       0       0       0       0       0  \n",
            "\n",
            "[5 rows x 48 columns]\n",
            "✅ Test Data Loaded Successfully:\n",
            "   AlertTitle  Category  IncidentGrade  EntityType  EvidenceRole  Url  \\\n",
            "0           5        11              0          28             0    0   \n",
            "1           2         1              0          15             0    0   \n",
            "2           5        11              0          23             1    0   \n",
            "3           0        10              1           7             1    0   \n",
            "4           5         5              0          28             0    0   \n",
            "\n",
            "   AccountName  DeviceName  CountryCode  State  ...  Hour_21  Hour_22  \\\n",
            "0            5           2            3      2  ...        0        1   \n",
            "1            4           5            3      2  ...        0        0   \n",
            "2            4           2            3      2  ...        0        0   \n",
            "3            4           2            3      2  ...        0        0   \n",
            "4            5           2            3      2  ...        0        0   \n",
            "\n",
            "   Hour_23  Hour_3  Hour_4  Hour_5  Hour_6  Hour_7  Hour_8  Hour_9  \n",
            "0        0       0       0       0       0       0       0       0  \n",
            "1        0       0       0       0       0       0       0       0  \n",
            "2        0       1       0       0       0       0       0       0  \n",
            "3        0       0       0       0       0       0       0       0  \n",
            "4        0       0       0       0       0       0       0       0  \n",
            "\n",
            "[5 rows x 48 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data['IncidentGrade'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgSEGi3vnWw4",
        "outputId": "cd01cba6-cfa1-4e69-c136-260f4408d230"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IncidentGrade\n",
            "0    1630942\n",
            "2    1422856\n",
            "1     868897\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost lightgbm imbalanced-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWzWdDLTnWzg",
        "outputId": "a37d07a3-24fb-4c58-9c4b-35e92352027d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xgboost\n",
            "  Downloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting lightgbm\n",
            "  Downloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n",
            "Collecting imbalanced-learn\n",
            "  Downloading imbalanced_learn-0.13.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.26.4)\n",
            "Collecting nvidia-nccl-cu12 (from xgboost)\n",
            "  Downloading nvidia_nccl_cu12-2.25.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Collecting sklearn-compat<1,>=0.1 (from imbalanced-learn)\n",
            "  Downloading sklearn_compat-0.1.3-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Downloading xgboost-2.1.4-py3-none-manylinux_2_28_x86_64.whl (223.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightgbm-4.5.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading imbalanced_learn-0.13.0-py3-none-any.whl (238 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.4/238.4 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sklearn_compat-0.1.3-py3-none-any.whl (18 kB)\n",
            "Downloading nvidia_nccl_cu12-2.25.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost, lightgbm, sklearn-compat, imbalanced-learn\n",
            "Successfully installed imbalanced-learn-0.13.0 lightgbm-4.5.0 nvidia-nccl-cu12-2.25.1 sklearn-compat-0.1.3 xgboost-2.1.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# Import Necessary Libraries\n",
        "# ===========================\n",
        "\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import warnings\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.combine import SMOTEENN\n",
        "\n"
      ],
      "metadata": {
        "id": "kaSPFGeSnW2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "8s778ufSnW44",
        "outputId": "5481ad28-1874-4a62-dd77-23772c92de60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         AlertTitle  Category  IncidentGrade  EntityType  EvidenceRole  Url  \\\n",
              "0                 4        17              1          26             0    0   \n",
              "1                 4        16              2          26             0    0   \n",
              "2                 4        17              0          14             0    0   \n",
              "3                 3         8              0          20             1    0   \n",
              "4                 4         2              2          26             0    0   \n",
              "...             ...       ...            ...         ...           ...  ...   \n",
              "6579287           4        16              1          28             0    0   \n",
              "6579288           0         2              2          26             0    0   \n",
              "6579289           4         2              2          29             1    0   \n",
              "6579290           4        17              0          14             0    0   \n",
              "6579291           4        17              0          14             0    0   \n",
              "\n",
              "         AccountName  DeviceName  CountryCode  State  ...  Hour_21  Hour_22  \\\n",
              "0                  4           0            0      0  ...        0        0   \n",
              "1                  4           0            0      0  ...        0        0   \n",
              "2                  3           0            0      0  ...        0        0   \n",
              "3                  3           0            0      0  ...        0        0   \n",
              "4                  4           0            0      0  ...        0        0   \n",
              "...              ...         ...          ...    ...  ...      ...      ...   \n",
              "6579287            3           0            0      0  ...        0        0   \n",
              "6579288            4           0            0      0  ...        0        0   \n",
              "6579289            3           0            0      0  ...        0        0   \n",
              "6579290            3           0            0      0  ...        0        1   \n",
              "6579291            3           0            0      0  ...        0        0   \n",
              "\n",
              "         Hour_23  Hour_3  Hour_4  Hour_5  Hour_6  Hour_7  Hour_8  Hour_9  \n",
              "0              0       1       0       0       0       0       0       0  \n",
              "1              0       0       0       0       0       0       0       0  \n",
              "2              0       0       0       0       0       0       0       0  \n",
              "3              0       0       0       0       0       0       0       0  \n",
              "4              0       0       0       0       0       0       0       0  \n",
              "...          ...     ...     ...     ...     ...     ...     ...     ...  \n",
              "6579287        0       0       1       0       0       0       0       0  \n",
              "6579288        0       0       0       0       0       0       0       0  \n",
              "6579289        0       0       0       0       0       0       0       0  \n",
              "6579290        0       0       0       0       0       0       0       0  \n",
              "6579291        1       0       0       0       0       0       0       0  \n",
              "\n",
              "[6579292 rows x 48 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-374651c8-f4b4-4c17-a061-e7a8b3f7f2ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AlertTitle</th>\n",
              "      <th>Category</th>\n",
              "      <th>IncidentGrade</th>\n",
              "      <th>EntityType</th>\n",
              "      <th>EvidenceRole</th>\n",
              "      <th>Url</th>\n",
              "      <th>AccountName</th>\n",
              "      <th>DeviceName</th>\n",
              "      <th>CountryCode</th>\n",
              "      <th>State</th>\n",
              "      <th>...</th>\n",
              "      <th>Hour_21</th>\n",
              "      <th>Hour_22</th>\n",
              "      <th>Hour_23</th>\n",
              "      <th>Hour_3</th>\n",
              "      <th>Hour_4</th>\n",
              "      <th>Hour_5</th>\n",
              "      <th>Hour_6</th>\n",
              "      <th>Hour_7</th>\n",
              "      <th>Hour_8</th>\n",
              "      <th>Hour_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6579287</th>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6579288</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6579289</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6579290</th>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6579291</th>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6579292 rows × 48 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-374651c8-f4b4-4c17-a061-e7a8b3f7f2ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-374651c8-f4b4-4c17-a061-e7a8b3f7f2ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-374651c8-f4b4-4c17-a061-e7a8b3f7f2ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6f903733-8ac7-4956-ae13-04e865a57318\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6f903733-8ac7-4956-ae13-04e865a57318')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6f903733-8ac7-4956-ae13-04e865a57318 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9d11f738-cc9f-4c71-ae32-b6f059871240\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9d11f738-cc9f-4c71-ae32-b6f059871240 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_data"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "2i385IdKnW7p",
        "outputId": "a5571a32-c43f-4232-c9e4-abcd19fc88ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         AlertTitle  Category  IncidentGrade  EntityType  EvidenceRole  Url  \\\n",
              "0                 5        11              0          28             0    0   \n",
              "1                 2         1              0          15             0    0   \n",
              "2                 5        11              0          23             1    0   \n",
              "3                 0        10              1           7             1    0   \n",
              "4                 5         5              0          28             0    0   \n",
              "...             ...       ...            ...         ...           ...  ...   \n",
              "3922690           5        12              0          15             0    0   \n",
              "3922691           5        10              0          28             0    0   \n",
              "3922692           5        10              0          28             0    0   \n",
              "3922693           5         1              1          12             1    0   \n",
              "3922694           1        10              0          18             0    0   \n",
              "\n",
              "         AccountName  DeviceName  CountryCode  State  ...  Hour_21  Hour_22  \\\n",
              "0                  5           2            3      2  ...        0        1   \n",
              "1                  4           5            3      2  ...        0        0   \n",
              "2                  4           2            3      2  ...        0        0   \n",
              "3                  4           2            3      2  ...        0        0   \n",
              "4                  5           2            3      2  ...        0        0   \n",
              "...              ...         ...          ...    ...  ...      ...      ...   \n",
              "3922690            4           3            3      2  ...        0        0   \n",
              "3922691            5           2            3      2  ...        0        0   \n",
              "3922692            5           2            3      2  ...        0        0   \n",
              "3922693            4           2            3      2  ...        0        0   \n",
              "3922694            5           2            3      2  ...        0        0   \n",
              "\n",
              "         Hour_23  Hour_3  Hour_4  Hour_5  Hour_6  Hour_7  Hour_8  Hour_9  \n",
              "0              0       0       0       0       0       0       0       0  \n",
              "1              0       0       0       0       0       0       0       0  \n",
              "2              0       1       0       0       0       0       0       0  \n",
              "3              0       0       0       0       0       0       0       0  \n",
              "4              0       0       0       0       0       0       0       0  \n",
              "...          ...     ...     ...     ...     ...     ...     ...     ...  \n",
              "3922690        0       0       0       0       0       0       0       0  \n",
              "3922691        0       1       0       0       0       0       0       0  \n",
              "3922692        0       0       0       0       0       0       0       0  \n",
              "3922693        0       0       0       0       0       0       0       0  \n",
              "3922694        0       0       0       0       0       0       0       0  \n",
              "\n",
              "[3922695 rows x 48 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-032eedd8-5f7a-4d88-ba79-62ac79760ea3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AlertTitle</th>\n",
              "      <th>Category</th>\n",
              "      <th>IncidentGrade</th>\n",
              "      <th>EntityType</th>\n",
              "      <th>EvidenceRole</th>\n",
              "      <th>Url</th>\n",
              "      <th>AccountName</th>\n",
              "      <th>DeviceName</th>\n",
              "      <th>CountryCode</th>\n",
              "      <th>State</th>\n",
              "      <th>...</th>\n",
              "      <th>Hour_21</th>\n",
              "      <th>Hour_22</th>\n",
              "      <th>Hour_23</th>\n",
              "      <th>Hour_3</th>\n",
              "      <th>Hour_4</th>\n",
              "      <th>Hour_5</th>\n",
              "      <th>Hour_6</th>\n",
              "      <th>Hour_7</th>\n",
              "      <th>Hour_8</th>\n",
              "      <th>Hour_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3922690</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3922691</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3922692</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3922693</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3922694</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3922695 rows × 48 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-032eedd8-5f7a-4d88-ba79-62ac79760ea3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-032eedd8-5f7a-4d88-ba79-62ac79760ea3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-032eedd8-5f7a-4d88-ba79-62ac79760ea3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b0e1eeba-61b5-4704-8a46-d284ba016511\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b0e1eeba-61b5-4704-8a46-d284ba016511')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b0e1eeba-61b5-4704-8a46-d284ba016511 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_aba1c0c6-601e-49c4-b5bc-dea141879ec5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_aba1c0c6-601e-49c4-b5bc-dea141879ec5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Display dataset information\n",
        "print(\"\\nTrain Data Loaded Successfully!\")\n",
        "print(\"Train Data Shape:\", train_data.shape)\n",
        "\n",
        "print(\"\\nTest Data Loaded Successfully!\")\n",
        "print(\"Test Data Shape:\", test_data.shape)\n",
        "\n",
        "# Separateing features (X) and target variable (y)\n",
        "X = train_data.drop(columns=['IncidentGrade'])\n",
        "y = train_data['IncidentGrade']\n",
        "\n",
        "# Spliting the data (80:20)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Step 4: Display split dataset shapes\n",
        "print(\"\\nSplitting Completed!\")\n",
        "print(\"X_train Shape:\", X_train.shape)\n",
        "print(\"X_val Shape:\", X_val.shape)\n",
        "print(\"y_train Shape:\", y_train.shape)\n",
        "print(\"y_val Shape:\", y_val.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U7ztlBHnW-J",
        "outputId": "a3d676df-cc9d-446a-c9fb-be82f86ee08b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train Data Loaded Successfully!\n",
            "Train Data Shape: (6579292, 48)\n",
            "\n",
            "Test Data Loaded Successfully!\n",
            "Test Data Shape: (3922695, 48)\n",
            "\n",
            "Splitting Completed!\n",
            "X_train Shape: (5263433, 47)\n",
            "X_val Shape: (1315859, 47)\n",
            "y_train Shape: (5263433,)\n",
            "y_val Shape: (1315859,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparing Machine Learning Models**"
      ],
      "metadata": {
        "id": "HN337esCnw-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_subsample = X_train.sample(frac=0.1, random_state=42)\n",
        "y_train_subsample = y_train.loc[X_train_subsample.index]\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_jobs=-1, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "    'XGBoost': XGBClassifier(n_jobs=-1, random_state=42),\n",
        "    'LightGBM': LGBMClassifier(n_jobs=-1, random_state=42),\n",
        "}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    print(f'Model: {model_name}')\n",
        "\n",
        "    model.fit(X_train_subsample, y_train_subsample)\n",
        "\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    # Evaluateing the models\n",
        "    accuracy = accuracy_score(y_val, y_pred)\n",
        "    report = classification_report(y_val, y_pred)\n",
        "    cm = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "    # Displaying the results of the modles\n",
        "    print(f'Accuracy: {accuracy}')\n",
        "    print('Classification Report:')\n",
        "    print(report)\n",
        "    print('Confusion Matrix:')\n",
        "    print(cm)\n",
        "    print('-' * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fe3CeioLnXEI",
        "outputId": "9221911a-48d3-484d-c9ba-6e6544a0e202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: Logistic Regression\n",
            "Accuracy: 0.5846766256870987\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.82      0.68    604084\n",
            "           1       0.15      0.01      0.01    288708\n",
            "           2       0.58      0.65      0.62    423067\n",
            "\n",
            "    accuracy                           0.58   1315859\n",
            "   macro avg       0.44      0.49      0.44   1315859\n",
            "weighted avg       0.49      0.58      0.51   1315859\n",
            "\n",
            "Confusion Matrix:\n",
            "[[492967   4987 106130]\n",
            " [197676   1451  89581]\n",
            " [145135   2998 274934]]\n",
            "--------------------------------------------------\n",
            "Model: Random Forest\n",
            "Accuracy: 0.6826612881775327\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.84      0.75    604084\n",
            "           1       0.63      0.38      0.47    288708\n",
            "           2       0.72      0.67      0.69    423067\n",
            "\n",
            "    accuracy                           0.68   1315859\n",
            "   macro avg       0.68      0.63      0.64   1315859\n",
            "weighted avg       0.68      0.68      0.67   1315859\n",
            "\n",
            "Confusion Matrix:\n",
            "[[504606  40698  58780]\n",
            " [125969 109509  53230]\n",
            " [116433  22463 284171]]\n",
            "--------------------------------------------------\n",
            "Model: Decision Tree\n",
            "Accuracy: 0.682761602876904\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.84      0.75    604084\n",
            "           1       0.64      0.38      0.47    288708\n",
            "           2       0.72      0.66      0.69    423067\n",
            "\n",
            "    accuracy                           0.68   1315859\n",
            "   macro avg       0.68      0.63      0.64   1315859\n",
            "weighted avg       0.68      0.68      0.67   1315859\n",
            "\n",
            "Confusion Matrix:\n",
            "[[509373  39481  55230]\n",
            " [128507 109015  51186]\n",
            " [119984  23053 280030]]\n",
            "--------------------------------------------------\n",
            "Model: Gradient Boosting\n",
            "Accuracy: 0.6393944943949161\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.92      0.73    604084\n",
            "           1       0.76      0.13      0.22    288708\n",
            "           2       0.71      0.59      0.64    423067\n",
            "\n",
            "    accuracy                           0.64   1315859\n",
            "   macro avg       0.69      0.55      0.53   1315859\n",
            "weighted avg       0.67      0.64      0.59   1315859\n",
            "\n",
            "Confusion Matrix:\n",
            "[[553713   4753  45618]\n",
            " [192920  37713  58075]\n",
            " [165842   7298 249927]]\n",
            "--------------------------------------------------\n",
            "Model: XGBoost\n",
            "Accuracy: 0.6745433971268958\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.89      0.75    604084\n",
            "           1       0.69      0.28      0.40    288708\n",
            "           2       0.74      0.63      0.68    423067\n",
            "\n",
            "    accuracy                           0.67   1315859\n",
            "   macro avg       0.69      0.60      0.61   1315859\n",
            "weighted avg       0.68      0.67      0.65   1315859\n",
            "\n",
            "Confusion Matrix:\n",
            "[[537076  21769  45239]\n",
            " [155994  82265  50449]\n",
            " [139391  15413 268263]]\n",
            "--------------------------------------------------\n",
            "Model: LightGBM\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.013009 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 132\n",
            "[LightGBM] [Info] Number of data points in the train set: 526343, number of used features: 43\n",
            "[LightGBM] [Info] Start training from score -0.776437\n",
            "[LightGBM] [Info] Start training from score -1.517003\n",
            "[LightGBM] [Info] Start training from score -1.137594\n",
            "Accuracy: 0.667357216844662\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.91      0.75    604084\n",
            "           1       0.70      0.25      0.37    288708\n",
            "           2       0.75      0.61      0.67    423067\n",
            "\n",
            "    accuracy                           0.67   1315859\n",
            "   macro avg       0.69      0.59      0.60   1315859\n",
            "weighted avg       0.68      0.67      0.64   1315859\n",
            "\n",
            "Confusion Matrix:\n",
            "[[549125  15682  39277]\n",
            " [167994  72696  48018]\n",
            " [151681  15059 256327]]\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ✅ Creating the report data with updated values\n",
        "report = {\n",
        "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost', 'LightGBM', 'Gradient Boosting'],\n",
        "    'Accuracy': [0.5847, 0.6828, 0.6827, 0.6745, 0.6700, 0.6394],  # Updated LightGBM accuracy to 0.67\n",
        "    'Macro-F1 Score': [0.44, 0.64, 0.64, 0.60, 0.60, 0.53],\n",
        "    'Precision': [0.44, 0.68, 0.68, 0.69, 0.69, 0.67],\n",
        "    'Recall': [0.49, 0.63, 0.63, 0.60, 0.59, 0.55]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(report)\n",
        "\n",
        "print(\"Comparison Table:\")\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "best_models_with_max_f1 = df[df['Macro-F1 Score'] == df['Macro-F1 Score'].max()]\n",
        "\n",
        "if len(best_models_with_max_f1) > 1:\n",
        "    best_model = best_models_with_max_f1.loc[best_models_with_max_f1['Accuracy'].idxmax()]\n",
        "else:\n",
        "    best_model = df.loc[df['Macro-F1 Score'].idxmax()]\n",
        "\n",
        "print(\"\\nBest Model Based on Macro-F1 Score (and Accuracy in case of a tie):\")\n",
        "print(best_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyK8w-SinXGx",
        "outputId": "60245a4b-e16d-40e3-bace-76abe4463ff4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison Table:\n",
            "              Model  Accuracy  Macro-F1 Score  Precision  Recall\n",
            "Logistic Regression    0.5847            0.44       0.44    0.49\n",
            "      Decision Tree    0.6828            0.64       0.68    0.63\n",
            "      Random Forest    0.6827            0.64       0.68    0.63\n",
            "            XGBoost    0.6745            0.60       0.69    0.60\n",
            "           LightGBM    0.6700            0.60       0.69    0.59\n",
            "  Gradient Boosting    0.6394            0.53       0.67    0.55\n",
            "\n",
            "Best Model Based on Macro-F1 Score (and Accuracy in case of a tie):\n",
            "Model             Decision Tree\n",
            "Accuracy                 0.6828\n",
            "Macro-F1 Score             0.64\n",
            "Precision                  0.68\n",
            "Recall                     0.63\n",
            "Name: 1, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Applying Class Weights to Improve Model Performance on Train Data**"
      ],
      "metadata": {
        "id": "WmUQWNRrs-Ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Import Necessary Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "\n",
        "# ✅ Step 3: Prepare Features (X) and Target (y)\n",
        "X_train = train_data.drop(columns=['IncidentGrade'])\n",
        "y_train = train_data['IncidentGrade']\n",
        "\n",
        "# ✅ Step 4: Compute Class Weights\n",
        "class_counts = y_train.value_counts()\n",
        "total_samples = class_counts.sum()\n",
        "\n",
        "class_weights = {\n",
        "    0: round(total_samples / (3 * class_counts[0]), 2),\n",
        "    1: round(total_samples / (3 * class_counts[1]), 2),\n",
        "    2: round(total_samples / (3 * class_counts[2]), 2)\n",
        "}\n",
        "\n",
        "print(\"📊 Computed Class Weights:\", class_weights)\n",
        "\n",
        "# ✅ Step 5: Subsample Training Data (10% for Faster Training)\n",
        "X_train_subsample = X_train.sample(frac=0.1, random_state=42)\n",
        "y_train_subsample = y_train.loc[X_train_subsample.index]\n",
        "\n",
        "# ✅ Step 6: Define Multiple Models with Class Weights\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, class_weight=class_weights, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_jobs=-1, class_weight=class_weights, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(class_weight=class_weights, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),  # No class_weight support\n",
        "    'XGBoost': XGBClassifier(n_jobs=-1, scale_pos_weight=class_weights[1], random_state=42),  # Only supports binary weight\n",
        "    'LightGBM': LGBMClassifier(n_jobs=-1, class_weight=class_weights, random_state=42),\n",
        "}\n",
        "\n",
        "# ✅ Step 7: Train and Evaluate Models\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\n🚀 Training Model: {model_name}\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train_subsample, y_train_subsample)\n",
        "\n",
        "    # Make predictions on the validation set\n",
        "    y_pred = model.predict(X_train)\n",
        "\n",
        "    # Evaluate the model\n",
        "    accuracy = accuracy_score(y_train, y_pred)\n",
        "    report = classification_report(y_train, y_pred)\n",
        "    cm = confusion_matrix(y_train, y_pred)\n",
        "\n",
        "    # Display results\n",
        "    print(f\"\\n🔹 Accuracy: {accuracy:.4f}\")\n",
        "    print(\"\\n📊 Classification Report:\")\n",
        "    print(report)\n",
        "    print(\"\\n📌 Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    print(\"-\" * 80)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLy73cRInXJS",
        "outputId": "5a798ffa-7aaa-49d5-bcf2-e60cdccb3d51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Computed Class Weights: {0: 0.73, 1: 1.52, 2: 1.04}\n",
            "\n",
            "🚀 Training Model: Logistic Regression\n",
            "\n",
            "🔹 Accuracy: 0.5393\n",
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.57      0.60   3020419\n",
            "           1       0.30      0.28      0.29   1443539\n",
            "           2       0.57      0.67      0.61   2115334\n",
            "\n",
            "    accuracy                           0.54   6579292\n",
            "   macro avg       0.50      0.51      0.50   6579292\n",
            "weighted avg       0.54      0.54      0.54   6579292\n",
            "\n",
            "\n",
            "📌 Confusion Matrix:\n",
            "[[1729747  666414  624258]\n",
            " [ 596788  409781  436970]\n",
            " [ 398221  308550 1408563]]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "🚀 Training Model: Random Forest\n",
            "\n",
            "🔹 Accuracy: 0.6636\n",
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.70      0.71   3020419\n",
            "           1       0.51      0.55      0.52   1443539\n",
            "           2       0.70      0.70      0.70   2115334\n",
            "\n",
            "    accuracy                           0.66   6579292\n",
            "   macro avg       0.64      0.65      0.64   6579292\n",
            "weighted avg       0.67      0.66      0.67   6579292\n",
            "\n",
            "\n",
            "📌 Confusion Matrix:\n",
            "[[2103318  538472  378629]\n",
            " [ 395483  787774  260282]\n",
            " [ 406760  233555 1475019]]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "🚀 Training Model: Decision Tree\n",
            "\n",
            "🔹 Accuracy: 0.6609\n",
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.69      0.71   3020419\n",
            "           1       0.50      0.55      0.52   1443539\n",
            "           2       0.70      0.70      0.70   2115334\n",
            "\n",
            "    accuracy                           0.66   6579292\n",
            "   macro avg       0.64      0.65      0.64   6579292\n",
            "weighted avg       0.67      0.66      0.66   6579292\n",
            "\n",
            "\n",
            "📌 Confusion Matrix:\n",
            "[[2070546  564941  384932]\n",
            " [ 382450  800352  260737]\n",
            " [ 396463  241300 1477571]]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "🚀 Training Model: Gradient Boosting\n",
            "\n",
            "🔹 Accuracy: 0.6399\n",
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.92      0.73   3020419\n",
            "           1       0.78      0.13      0.22   1443539\n",
            "           2       0.71      0.59      0.64   2115334\n",
            "\n",
            "    accuracy                           0.64   6579292\n",
            "   macro avg       0.70      0.55      0.53   6579292\n",
            "weighted avg       0.68      0.64      0.59   6579292\n",
            "\n",
            "\n",
            "📌 Confusion Matrix:\n",
            "[[2775998   19772  224649]\n",
            " [ 970717  185382  287440]\n",
            " [ 832805   33549 1248980]]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "🚀 Training Model: XGBoost\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [17:42:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"scale_pos_weight\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Accuracy: 0.6745\n",
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.89      0.75   3020419\n",
            "           1       0.69      0.28      0.40   1443539\n",
            "           2       0.73      0.64      0.68   2115334\n",
            "\n",
            "    accuracy                           0.67   6579292\n",
            "   macro avg       0.69      0.60      0.61   6579292\n",
            "weighted avg       0.68      0.67      0.65   6579292\n",
            "\n",
            "\n",
            "📌 Confusion Matrix:\n",
            "[[2673834  106266  240319]\n",
            " [ 779409  405463  258667]\n",
            " [ 681088   76074 1358172]]\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "🚀 Training Model: LightGBM\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022717 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 131\n",
            "[LightGBM] [Info] Number of data points in the train set: 657929, number of used features: 43\n",
            "[LightGBM] [Info] Start training from score -1.096137\n",
            "[LightGBM] [Info] Start training from score -1.098934\n",
            "[LightGBM] [Info] Start training from score -1.100771\n",
            "\n",
            "🔹 Accuracy: 0.6415\n",
            "\n",
            "📊 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.68      0.69   3020419\n",
            "           1       0.48      0.49      0.48   1443539\n",
            "           2       0.67      0.69      0.68   2115334\n",
            "\n",
            "    accuracy                           0.64   6579292\n",
            "   macro avg       0.62      0.62      0.62   6579292\n",
            "weighted avg       0.64      0.64      0.64   6579292\n",
            "\n",
            "\n",
            "📌 Confusion Matrix:\n",
            "[[2054008  536654  429757]\n",
            " [ 440239  704393  298907]\n",
            " [ 431194  221976 1462164]]\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ✅ Creating the report data with updated values\n",
        "report = {\n",
        "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost', 'LightGBM', 'Gradient Boosting'],\n",
        "    'Accuracy': [0.5393, 0.6609, 0.6636, 0.6745, 0.6415, 0.6399],  # Updated LightGBM accuracy\n",
        "    'Macro-F1 Score': [0.50, 0.64, 0.64, 0.61, 0.62, 0.53],\n",
        "    'Precision': [0.50, 0.64, 0.64, 0.69, 0.62, 0.70],\n",
        "    'Recall': [0.51, 0.65, 0.65, 0.60, 0.62, 0.55]\n",
        "}\n",
        "\n",
        "\n",
        "df = pd.DataFrame(report)\n",
        "\n",
        "print(\"Comparison Table:\")\n",
        "print(df.to_string(index=False))\n",
        "\n",
        "best_models_with_max_f1 = df[df['Macro-F1 Score'] == df['Macro-F1 Score'].max()]\n",
        "\n",
        "if len(best_models_with_max_f1) > 1:\n",
        "    best_model = best_models_with_max_f1.loc[best_models_with_max_f1['Accuracy'].idxmax()]\n",
        "else:\n",
        "    best_model = df.loc[df['Macro-F1 Score'].idxmax()]\n",
        "\n",
        "print(\"\\nBest Model Based on Macro-F1 Score (and Accuracy in case of a tie):\")\n",
        "print(best_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQg6IyhgnXMA",
        "outputId": "7d7b1e5e-1848-442e-9730-cdd85767357a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comparison Table:\n",
            "              Model  Accuracy  Macro-F1 Score  Precision  Recall\n",
            "Logistic Regression    0.5393            0.50       0.50    0.51\n",
            "      Decision Tree    0.6609            0.64       0.64    0.65\n",
            "      Random Forest    0.6636            0.64       0.64    0.65\n",
            "            XGBoost    0.6745            0.61       0.69    0.60\n",
            "           LightGBM    0.6415            0.62       0.62    0.62\n",
            "  Gradient Boosting    0.6399            0.53       0.70    0.55\n",
            "\n",
            "Best Model Based on Macro-F1 Score (and Accuracy in case of a tie):\n",
            "Model             Random Forest\n",
            "Accuracy                 0.6636\n",
            "Macro-F1 Score             0.64\n",
            "Precision                  0.64\n",
            "Recall                     0.65\n",
            "Name: 2, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Random Forest Model Training using SMOTE**\n",
        "This code trains a Random Forest classifier for multi-class classification on cybersecurity incident grades while handling class imbalance using SMOTE (Synthetic Minority Over-sampling Technique)."
      ],
      "metadata": {
        "id": "fjqv6weAwMA2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "# ✅ 2️⃣ Feature Selection & Preprocessing\n",
        "X = train_data.drop('IncidentGrade', axis=1)\n",
        "y = train_data['IncidentGrade']\n",
        "\n",
        "# Convert to numeric and remove NaN columns\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "X = X.dropna(axis=1)\n",
        "\n",
        "# ✅ 3️⃣ Feature Scaling (NEW)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ✅ 4️⃣ Train-Test Split (80:20)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# ✅ 5️⃣ Increase Training Data Percentage (NOW 5% instead of 2%)\n",
        "X_train_sampled, _, y_train_sampled, _ = train_test_split(X_train, y_train, train_size=0.05, stratify=y_train, random_state=42)\n",
        "\n",
        "# ✅ 6️⃣ Apply SMOTE for Balancing Classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_sampled, y_train_sampled)\n",
        "\n",
        "# ✅ 7️⃣ Hyperparameter Tuning (Expanded Search Space)\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],  # More estimators\n",
        "    'max_depth': [10, 20, 30, None], # More depth variations\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False],\n",
        "    'max_features': ['sqrt', 'log2']  # NEW - Limits features used in each tree\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,  # Increased iterations for better search\n",
        "    cv=5,  # More cross-validation folds\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# ✅ 8️⃣ Train with Optimized Hyperparameters\n",
        "random_search.fit(X_train_resampled, y_train_resampled)\n",
        "best_rf = random_search.best_estimator_\n",
        "\n",
        "# ✅ 9️⃣ Evaluate on Validation Data\n",
        "y_pred = best_rf.predict(X_val)\n",
        "\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# ✅ 🔟 Save the Tuned Model\n",
        "joblib.dump(best_rf, \"rf_1smote_tuned_model_optimized.joblib\")\n",
        "print(\"✅ Model saved as rf_smote_tuned_model_optimized.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_VwS86znXOp",
        "outputId": "1f033726-e38d-4616-8337-64f06af15811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_estimators': 150, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.69      0.70    604084\n",
            "           1       0.49      0.52      0.50    288708\n",
            "           2       0.69      0.69      0.69    423067\n",
            "\n",
            "    accuracy                           0.65   1315859\n",
            "   macro avg       0.63      0.63      0.63   1315859\n",
            "weighted avg       0.65      0.65      0.65   1315859\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[419514 106916  77654]\n",
            " [ 85634 148923  54151]\n",
            " [ 85799  47335 289933]]\n",
            "✅ Model saved as rf_smote_tuned_model_optimized.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest Model Training smote_tuned_model_weighted**"
      ],
      "metadata": {
        "id": "67wlsjdzwcJL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 2️⃣ Feature Selection & Preprocessing\n",
        "X = train_data.drop('IncidentGrade', axis=1)\n",
        "y = train_data['IncidentGrade']\n",
        "\n",
        "# Convert to numeric and remove NaN columns\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "X = X.dropna(axis=1)\n",
        "\n",
        "# ✅ 3️⃣ Feature Scaling (NEW)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ✅ 4️⃣ Train-Test Split (80:20)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# ✅ 5️⃣ Increase Training Data Percentage (NOW 5% instead of 2%)\n",
        "X_train_sampled, _, y_train_sampled, _ = train_test_split(X_train, y_train, train_size=0.05, stratify=y_train, random_state=42)\n",
        "\n",
        "# ✅ 6️⃣ Apply SMOTE for Balancing Classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_sampled, y_train_sampled)\n",
        "\n",
        "# ✅ 7️⃣ Compute Class Weights\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train_resampled), y=y_train_resampled)\n",
        "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "print(\"📊 Computed Class Weights:\", class_weights_dict)\n",
        "\n",
        "# ✅ 8️⃣ Hyperparameter Tuning (Expanded Search Space)\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1, class_weight=class_weights_dict)  # ✅ Apply class weights here\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# ✅ 9️⃣ Train with Optimized Hyperparameters\n",
        "random_search.fit(X_train_resampled, y_train_resampled)\n",
        "best_rf = random_search.best_estimator_\n",
        "\n",
        "# ✅ 🔟 Evaluate on Validation Data\n",
        "y_pred = best_rf.predict(X_val)\n",
        "\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# ✅ 1️⃣1️⃣ Save the Tuned Model\n",
        "joblib.dump(best_rf, \"rf_smote_tuned_model_weighted.joblib\")\n",
        "print(\"✅ Model saved as rf_smote_tuned_model_weighted.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSZ5eS6anXRw",
        "outputId": "6f8acff5-bec9-4645-8c3c-041246fff242"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Computed Class Weights: {0: 1.0, 1: 1.0, 2: 1.0}\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_estimators': 150, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.69      0.70    604084\n",
            "           1       0.49      0.52      0.50    288708\n",
            "           2       0.69      0.69      0.69    423067\n",
            "\n",
            "    accuracy                           0.65   1315859\n",
            "   macro avg       0.63      0.63      0.63   1315859\n",
            "weighted avg       0.65      0.65      0.65   1315859\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[419514 106916  77654]\n",
            " [ 85634 148923  54151]\n",
            " [ 85799  47335 289933]]\n",
            "✅ Model saved as rf_smote_tuned_model_weighted.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cost-Sensitive Learning (Using Class Weights + Misclassification Penalty)**"
      ],
      "metadata": {
        "id": "-pREccyJ0CdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 2️⃣ Feature Selection & Preprocessing\n",
        "X = train_data.drop('IncidentGrade', axis=1)\n",
        "y = train_data['IncidentGrade']\n",
        "\n",
        "# Convert to numeric and remove NaN columns\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "X = X.dropna(axis=1)\n",
        "\n",
        "# ✅ 3️⃣ Feature Scaling (NEW)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ✅ 4️⃣ Train-Test Split (80:20)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# ✅ 5️⃣ Increase Training Data Percentage (NOW 5% instead of 2%)\n",
        "X_train_sampled, _, y_train_sampled, _ = train_test_split(X_train, y_train, train_size=0.05, stratify=y_train, random_state=42)\n",
        "\n",
        "# ✅ 6️⃣ Apply SMOTE for Balancing Classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_sampled, y_train_sampled)\n",
        "\n",
        "# ✅ 7️⃣ Compute Sample Weights for Cost-Sensitive Learning\n",
        "sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train_resampled)\n",
        "print(\"📊 Computed Sample Weights for Cost-Sensitive Learning:\", sample_weights)\n",
        "\n",
        "# ✅ 8️⃣ Hyperparameter Tuning (Expanded Search Space)\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)  # No need to set class_weight manually as sample_weight is used\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# ✅ 9️⃣ Train with Cost-Sensitive Learning using Sample Weights\n",
        "random_search.fit(X_train_resampled, y_train_resampled, sample_weight=sample_weights)\n",
        "best_rf = random_search.best_estimator_\n",
        "\n",
        "# ✅ 🔟 Evaluate on Validation Data\n",
        "y_pred = best_rf.predict(X_val)\n",
        "\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# ✅ 1️⃣1️⃣ Save the Tuned Model\n",
        "joblib.dump(best_rf, \"rf_cost_sensitive_model.joblib\")\n",
        "print(\"✅ Model saved as rf_cost_sensitive_model.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ez2tmtWunXUh",
        "outputId": "070c807e-e141-4c5c-b914-bcdb79b4ca87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Computed Sample Weights for Cost-Sensitive Learning: [1. 1. 1. ... 1. 1. 1.]\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_estimators': 150, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.69      0.70    604084\n",
            "           1       0.49      0.52      0.50    288708\n",
            "           2       0.69      0.69      0.69    423067\n",
            "\n",
            "    accuracy                           0.65   1315859\n",
            "   macro avg       0.63      0.63      0.63   1315859\n",
            "weighted avg       0.65      0.65      0.65   1315859\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[419514 106916  77654]\n",
            " [ 85634 148923  54151]\n",
            " [ 85799  47335 289933]]\n",
            "✅ Model saved as rf_cost_sensitive_model.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Optimization (Hyperparameter Tuning on a Larger Scale)**\n",
        " Code incorporating Model Optimization with Larger-Scale Hyperparameter Tuning using Optuna instead of RandomizedSearchCV. This approach allows Bayesian Optimization, which intelligently explores the hyperparameter space to find the best configuration more efficiently.\n",
        "\n"
      ],
      "metadata": {
        "id": "piU_2q0l0xgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "\n",
        "import pandas as pd\n",
        "import joblib\n",
        "import optuna\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 2️⃣ Feature Selection & Preprocessing\n",
        "X = train_data.drop('IncidentGrade', axis=1)\n",
        "y = train_data['IncidentGrade']\n",
        "\n",
        "# Convert to numeric and remove NaN columns\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "X = X.dropna(axis=1)\n",
        "\n",
        "# ✅ 3️⃣ Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ✅ 4️⃣ Train-Test Split (80:20)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# ✅ 5️⃣ Increase Training Data Percentage (5% instead of 2%)\n",
        "X_train_sampled, _, y_train_sampled, _ = train_test_split(X_train, y_train, train_size=0.05, stratify=y_train, random_state=42)\n",
        "\n",
        "# ✅ 6️⃣ Apply SMOTE for Balancing Classes\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_sampled, y_train_sampled)\n",
        "\n",
        "# ✅ 7️⃣ Compute Sample Weights for Cost-Sensitive Learning\n",
        "sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train_resampled)\n",
        "print(\"📊 Computed Sample Weights for Cost-Sensitive Learning:\", sample_weights)\n",
        "\n",
        "# ✅ 8️⃣ Define Optuna Hyperparameter Optimization Function\n",
        "def objective(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
        "    max_depth = trial.suggest_int('max_depth', 10, 50)\n",
        "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
        "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 4)\n",
        "    bootstrap = trial.suggest_categorical('bootstrap', [True, False])\n",
        "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2'])\n",
        "\n",
        "    # Define model with trial parameters\n",
        "    model = RandomForestClassifier(\n",
        "        n_estimators=n_estimators,\n",
        "        max_depth=max_depth,\n",
        "        min_samples_split=min_samples_split,\n",
        "        min_samples_leaf=min_samples_leaf,\n",
        "        bootstrap=bootstrap,\n",
        "        max_features=max_features,\n",
        "        class_weight='balanced',\n",
        "        random_state=42,\n",
        "        n_jobs=-1\n",
        "    )\n",
        "\n",
        "    # Train using sample weights\n",
        "    model.fit(X_train_resampled, y_train_resampled, sample_weight=sample_weights)\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    accuracy = model.score(X_val, y_val)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "# ✅ 9️⃣ Run Bayesian Hyperparameter Optimization\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=20)  # You can increase n_trials for better tuning\n",
        "print(\"Best Hyperparameters:\", study.best_params)  # ✅ FIXED ATTRIBUTE NAME\n",
        "\n",
        "# ✅ 🔟 Train the Best Model from Optimization\n",
        "best_rf = RandomForestClassifier(**study.best_params, class_weight='balanced', random_state=42, n_jobs=-1)\n",
        "best_rf.fit(X_train_resampled, y_train_resampled, sample_weight=sample_weights)\n",
        "\n",
        "# ✅ 1️⃣1️⃣ Evaluate on Validation Data\n",
        "y_pred = best_rf.predict(X_val)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# ✅ 1️⃣2️⃣ Save the Optimized Model\n",
        "joblib.dump(best_rf, \"rf_optimized_optuna.joblib\")\n",
        "print(\"✅ Model saved as rf_optimized_optuna.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjO4FucsnXXx",
        "outputId": "d8a5cdef-3c82-4db7-e094-b0b43775f9c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.1-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Collecting sqlalchemy>=1.4.2 (from optuna)\n",
            "  Downloading SQLAlchemy-2.0.38-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Collecting greenlet!=0.4.17 (from sqlalchemy>=1.4.2->optuna)\n",
            "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.2.0-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.4/383.4 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.6/233.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SQLAlchemy-2.0.38-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.9-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, greenlet, colorlog, sqlalchemy, alembic, optuna\n",
            "Successfully installed Mako-1.3.9 alembic-1.14.1 colorlog-6.9.0 greenlet-3.1.1 optuna-4.2.0 sqlalchemy-2.0.38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-11 18:12:29,186] A new study created in memory with name: no-name-835df592-bbd5-490c-9a2a-cbfff1abc2ef\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Computed Sample Weights for Cost-Sensitive Learning: [1. 1. 1. ... 1. 1. 1.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-02-11 18:12:56,150] Trial 0 finished with value: 0.6564685122038152 and parameters: {'n_estimators': 139, 'max_depth': 36, 'min_samples_split': 6, 'min_samples_leaf': 3, 'bootstrap': True, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.6564685122038152.\n",
            "[I 2025-02-11 18:13:37,987] Trial 1 finished with value: 0.6539097274100036 and parameters: {'n_estimators': 198, 'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 3, 'bootstrap': False, 'max_features': 'log2'}. Best is trial 0 with value: 0.6564685122038152.\n",
            "[I 2025-02-11 18:14:06,656] Trial 2 finished with value: 0.6367475542592329 and parameters: {'n_estimators': 258, 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 2, 'bootstrap': True, 'max_features': 'sqrt'}. Best is trial 0 with value: 0.6564685122038152.\n",
            "[I 2025-02-11 18:14:56,421] Trial 3 finished with value: 0.656605304975685 and parameters: {'n_estimators': 293, 'max_depth': 30, 'min_samples_split': 8, 'min_samples_leaf': 2, 'bootstrap': True, 'max_features': 'log2'}. Best is trial 3 with value: 0.656605304975685.\n",
            "[I 2025-02-11 18:15:16,579] Trial 4 finished with value: 0.6523533296500613 and parameters: {'n_estimators': 72, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 2, 'bootstrap': False, 'max_features': 'log2'}. Best is trial 3 with value: 0.656605304975685.\n",
            "[I 2025-02-11 18:16:10,629] Trial 5 finished with value: 0.6548885556887174 and parameters: {'n_estimators': 268, 'max_depth': 39, 'min_samples_split': 9, 'min_samples_leaf': 2, 'bootstrap': True, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.656605304975685.\n",
            "[I 2025-02-11 18:17:01,124] Trial 6 finished with value: 0.6529567377659764 and parameters: {'n_estimators': 180, 'max_depth': 46, 'min_samples_split': 10, 'min_samples_leaf': 3, 'bootstrap': False, 'max_features': 'sqrt'}. Best is trial 3 with value: 0.656605304975685.\n",
            "[I 2025-02-11 18:17:44,943] Trial 7 finished with value: 0.6568500120453635 and parameters: {'n_estimators': 187, 'max_depth': 24, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.6568500120453635.\n",
            "[I 2025-02-11 18:18:15,461] Trial 8 finished with value: 0.6566433029678712 and parameters: {'n_estimators': 127, 'max_depth': 31, 'min_samples_split': 2, 'min_samples_leaf': 4, 'bootstrap': False, 'max_features': 'log2'}. Best is trial 7 with value: 0.6568500120453635.\n",
            "[I 2025-02-11 18:18:27,677] Trial 9 finished with value: 0.649747427345939 and parameters: {'n_estimators': 54, 'max_depth': 43, 'min_samples_split': 3, 'min_samples_leaf': 1, 'bootstrap': True, 'max_features': 'log2'}. Best is trial 7 with value: 0.6568500120453635.\n",
            "[I 2025-02-11 18:19:09,613] Trial 10 finished with value: 0.6481644309914664 and parameters: {'n_estimators': 222, 'max_depth': 17, 'min_samples_split': 6, 'min_samples_leaf': 1, 'bootstrap': False, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.6568500120453635.\n",
            "[I 2025-02-11 18:19:39,123] Trial 11 finished with value: 0.6549858305487138 and parameters: {'n_estimators': 128, 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 4, 'bootstrap': False, 'max_features': 'log2'}. Best is trial 7 with value: 0.6568500120453635.\n",
            "[I 2025-02-11 18:20:05,421] Trial 12 finished with value: 0.6487108421191025 and parameters: {'n_estimators': 112, 'max_depth': 19, 'min_samples_split': 5, 'min_samples_leaf': 4, 'bootstrap': False, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.6568500120453635.\n",
            "[I 2025-02-11 18:20:42,575] Trial 13 finished with value: 0.6557731489468096 and parameters: {'n_estimators': 156, 'max_depth': 33, 'min_samples_split': 7, 'min_samples_leaf': 4, 'bootstrap': False, 'max_features': 'log2'}. Best is trial 7 with value: 0.6568500120453635.\n",
            "[I 2025-02-11 18:21:04,882] Trial 14 finished with value: 0.6560832125630481 and parameters: {'n_estimators': 89, 'max_depth': 25, 'min_samples_split': 4, 'min_samples_leaf': 1, 'bootstrap': False, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.6568500120453635.\n",
            "[I 2025-02-11 18:21:28,488] Trial 15 finished with value: 0.6279426595098715 and parameters: {'n_estimators': 216, 'max_depth': 10, 'min_samples_split': 3, 'min_samples_leaf': 3, 'bootstrap': False, 'max_features': 'log2'}. Best is trial 7 with value: 0.6568500120453635.\n",
            "[I 2025-02-11 18:21:55,974] Trial 16 finished with value: 0.6523419302524055 and parameters: {'n_estimators': 163, 'max_depth': 20, 'min_samples_split': 5, 'min_samples_leaf': 1, 'bootstrap': False, 'max_features': 'log2'}. Best is trial 7 with value: 0.6568500120453635.\n",
            "[I 2025-02-11 18:22:19,475] Trial 17 finished with value: 0.6539317662454716 and parameters: {'n_estimators': 106, 'max_depth': 50, 'min_samples_split': 7, 'min_samples_leaf': 4, 'bootstrap': False, 'max_features': 'sqrt'}. Best is trial 7 with value: 0.6568500120453635.\n",
            "[I 2025-02-11 18:22:55,203] Trial 18 finished with value: 0.6575339759047132 and parameters: {'n_estimators': 184, 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 3, 'bootstrap': False, 'max_features': 'sqrt'}. Best is trial 18 with value: 0.6575339759047132.\n",
            "[I 2025-02-11 18:23:40,755] Trial 19 finished with value: 0.6577239658656436 and parameters: {'n_estimators': 240, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False, 'max_features': 'sqrt'}. Best is trial 19 with value: 0.6577239658656436.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_estimators': 240, 'max_depth': 28, 'min_samples_split': 3, 'min_samples_leaf': 2, 'bootstrap': False, 'max_features': 'sqrt'}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.71      0.71    604084\n",
            "           1       0.51      0.50      0.50    288708\n",
            "           2       0.69      0.68      0.69    423067\n",
            "\n",
            "    accuracy                           0.66   1315859\n",
            "   macro avg       0.63      0.63      0.63   1315859\n",
            "weighted avg       0.66      0.66      0.66   1315859\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[431134  99401  73549]\n",
            " [ 89041 144874  54793]\n",
            " [ 91049  42554 289464]]\n",
            "✅ Model saved as rf_optimized_optuna.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advanced Sampling Techniques**\n",
        " **code incorporating ADASYN, SMOTEENN, and SMOTETomek to improve data balancing and model performance. These techniques help generate better synthetic samples and remove noise, making the model more robust. 🚀**"
      ],
      "metadata": {
        "id": "JNyZlQ_94KV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import ADASYN, SMOTE\n",
        "from imblearn.combine import SMOTEENN, SMOTETomek\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_sample_weight\n",
        "import numpy as np\n",
        "\n",
        "# ✅ 2️⃣ Feature Selection & Preprocessing\n",
        "X = train_data.drop('IncidentGrade', axis=1)\n",
        "y = train_data['IncidentGrade']\n",
        "\n",
        "# Convert to numeric and remove NaN columns\n",
        "X = X.apply(pd.to_numeric, errors='coerce')\n",
        "X = X.dropna(axis=1)\n",
        "\n",
        "# ✅ 3️⃣ Feature Scaling (NEW)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# ✅ 4️⃣ Train-Test Split (80:20)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# ✅ 5️⃣ Increase Training Data Percentage (NOW 5% instead of 2%)\n",
        "X_train_sampled, _, y_train_sampled, _ = train_test_split(X_train, y_train, train_size=0.05, stratify=y_train, random_state=42)\n",
        "\n",
        "# ✅ 6️⃣ Apply Advanced Sampling Techniques (Choose One)\n",
        "sampling_technique = \"SMOTETomek\"  # Change to \"ADASYN\" or \"SMOTEENN\" if needed\n",
        "\n",
        "if sampling_technique == \"ADASYN\":\n",
        "    print(\"🔹 Applying ADASYN - Selective Synthetic Sampling for Minority Classes\")\n",
        "    sampler = ADASYN(random_state=42)\n",
        "\n",
        "elif sampling_technique == \"SMOTEENN\":\n",
        "    print(\"🔹 Applying SMOTEENN - SMOTE + Edited Nearest Neighbors for Noise Removal\")\n",
        "    sampler = SMOTEENN(random_state=42)\n",
        "\n",
        "elif sampling_technique == \"SMOTETomek\":\n",
        "    print(\"🔹 Applying SMOTETomek - Balancing and Borderline Noise Removal\")\n",
        "    sampler = SMOTETomek(random_state=42)\n",
        "\n",
        "# Apply the chosen technique\n",
        "X_train_resampled, y_train_resampled = sampler.fit_resample(X_train_sampled, y_train_sampled)\n",
        "\n",
        "# ✅ 7️⃣ Compute Sample Weights for Cost-Sensitive Learning\n",
        "sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train_resampled)\n",
        "print(\"📊 Computed Sample Weights for Cost-Sensitive Learning:\", sample_weights)\n",
        "\n",
        "# ✅ 8️⃣ Hyperparameter Tuning (Expanded Search Space)\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    cv=5,\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# ✅ 9️⃣ Train with Optimized Hyperparameters & Sample Weights\n",
        "random_search.fit(X_train_resampled, y_train_resampled, sample_weight=sample_weights)\n",
        "best_rf = random_search.best_estimator_\n",
        "\n",
        "# ✅ 🔟 Evaluate on Validation Data\n",
        "y_pred = best_rf.predict(X_val)\n",
        "\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_val, y_pred))\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(confusion_matrix(y_val, y_pred))\n",
        "\n",
        "# ✅ 1️⃣1️⃣ Save the Tuned Model\n",
        "joblib.dump(best_rf, f\"rf_{sampling_technique}_optimized.joblib\")\n",
        "print(f\"✅ Model saved as rf_{sampling_technique}_optimized.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFhJMDxn3PiJ",
        "outputId": "45122725-03f8-40c3-b5d7-24a1ad85d50b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 Applying SMOTETomek - Balancing and Borderline Noise Removal\n",
            "📊 Computed Sample Weights for Cost-Sensitive Learning: [0.99880702 0.99957242 0.99880702 ... 0.99957242 0.99957242 0.99957242]\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'n_estimators': 150, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None, 'bootstrap': False}\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.69      0.70    604084\n",
            "           1       0.49      0.52      0.50    288708\n",
            "           2       0.69      0.68      0.69    423067\n",
            "\n",
            "    accuracy                           0.65   1315859\n",
            "   macro avg       0.63      0.63      0.63   1315859\n",
            "weighted avg       0.65      0.65      0.65   1315859\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[419026 107687  77371]\n",
            " [ 85491 149350  53867]\n",
            " [ 86147  48058 288862]]\n",
            "✅ Model saved as rf_SMOTETomek_optimized.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Data**\n",
        "**Evaluating the Saved Random Forest Model on Test Data**\n"
      ],
      "metadata": {
        "id": "ksqgQDhq4tJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "NG4N2JBV4re6",
        "outputId": "31dbb0e1-47ea-40ff-885d-138fa8d780bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         AlertTitle  Category  IncidentGrade  EntityType  EvidenceRole  Url  \\\n",
              "0                 5        11              0          28             0    0   \n",
              "1                 2         1              0          15             0    0   \n",
              "2                 5        11              0          23             1    0   \n",
              "3                 0        10              1           7             1    0   \n",
              "4                 5         5              0          28             0    0   \n",
              "...             ...       ...            ...         ...           ...  ...   \n",
              "3922690           5        12              0          15             0    0   \n",
              "3922691           5        10              0          28             0    0   \n",
              "3922692           5        10              0          28             0    0   \n",
              "3922693           5         1              1          12             1    0   \n",
              "3922694           1        10              0          18             0    0   \n",
              "\n",
              "         AccountName  DeviceName  CountryCode  State  ...  Hour_21  Hour_22  \\\n",
              "0                  5           2            3      2  ...        0        1   \n",
              "1                  4           5            3      2  ...        0        0   \n",
              "2                  4           2            3      2  ...        0        0   \n",
              "3                  4           2            3      2  ...        0        0   \n",
              "4                  5           2            3      2  ...        0        0   \n",
              "...              ...         ...          ...    ...  ...      ...      ...   \n",
              "3922690            4           3            3      2  ...        0        0   \n",
              "3922691            5           2            3      2  ...        0        0   \n",
              "3922692            5           2            3      2  ...        0        0   \n",
              "3922693            4           2            3      2  ...        0        0   \n",
              "3922694            5           2            3      2  ...        0        0   \n",
              "\n",
              "         Hour_23  Hour_3  Hour_4  Hour_5  Hour_6  Hour_7  Hour_8  Hour_9  \n",
              "0              0       0       0       0       0       0       0       0  \n",
              "1              0       0       0       0       0       0       0       0  \n",
              "2              0       1       0       0       0       0       0       0  \n",
              "3              0       0       0       0       0       0       0       0  \n",
              "4              0       0       0       0       0       0       0       0  \n",
              "...          ...     ...     ...     ...     ...     ...     ...     ...  \n",
              "3922690        0       0       0       0       0       0       0       0  \n",
              "3922691        0       1       0       0       0       0       0       0  \n",
              "3922692        0       0       0       0       0       0       0       0  \n",
              "3922693        0       0       0       0       0       0       0       0  \n",
              "3922694        0       0       0       0       0       0       0       0  \n",
              "\n",
              "[3922695 rows x 48 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51bef683-8fbb-48cc-913b-44f1fd29a530\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AlertTitle</th>\n",
              "      <th>Category</th>\n",
              "      <th>IncidentGrade</th>\n",
              "      <th>EntityType</th>\n",
              "      <th>EvidenceRole</th>\n",
              "      <th>Url</th>\n",
              "      <th>AccountName</th>\n",
              "      <th>DeviceName</th>\n",
              "      <th>CountryCode</th>\n",
              "      <th>State</th>\n",
              "      <th>...</th>\n",
              "      <th>Hour_21</th>\n",
              "      <th>Hour_22</th>\n",
              "      <th>Hour_23</th>\n",
              "      <th>Hour_3</th>\n",
              "      <th>Hour_4</th>\n",
              "      <th>Hour_5</th>\n",
              "      <th>Hour_6</th>\n",
              "      <th>Hour_7</th>\n",
              "      <th>Hour_8</th>\n",
              "      <th>Hour_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>23</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3922690</th>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3922691</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3922692</th>\n",
              "      <td>5</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3922693</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3922694</th>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3922695 rows × 48 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51bef683-8fbb-48cc-913b-44f1fd29a530')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-51bef683-8fbb-48cc-913b-44f1fd29a530 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-51bef683-8fbb-48cc-913b-44f1fd29a530');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b67bbc5-0e36-4798-a050-eec25a2c7510\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b67bbc5-0e36-4798-a050-eec25a2c7510')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b67bbc5-0e36-4798-a050-eec25a2c7510 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_718625d9-e328-4a39-b60d-1d6588742e51\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_718625d9-e328-4a39-b60d-1d6588742e51 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **\"Evaluating a Tuned Random Forest Model (rf_optimized_optuna.joblib) on Test Data\"**"
      ],
      "metadata": {
        "id": "1KuZ78Kx-iCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ✅ 1️⃣ Load the saved Random Forest model\n",
        "best_rf = joblib.load(\"rf_optimized_optuna.joblib\")\n",
        "\n",
        "# ✅ 2️⃣ Load & Preprocess the Test Data\n",
        "X_test = test_data.drop('IncidentGrade', axis=1)\n",
        "y_test = test_data['IncidentGrade']\n",
        "\n",
        "# Convert to numeric and handle missing values\n",
        "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
        "X_test = X_test.dropna(axis=1)\n",
        "\n",
        "# ✅ 3️⃣ Apply the same scaling used in training\n",
        "scaler = StandardScaler()\n",
        "X_test_scaled = scaler.fit_transform(X_test)  # Ensure this uses the same scaler fitted during training\n",
        "\n",
        "# ✅ 4️⃣ Make Predictions\n",
        "y_test_pred = best_rf.predict(X_test_scaled)\n",
        "\n",
        "# ✅ 5️⃣ Evaluate the Model\n",
        "print(\"\\n🔹 Classification Report on Test Data:\")\n",
        "report = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# Extract evaluation metrics\n",
        "macro_f1 = report['macro avg']['f1-score']\n",
        "macro_precision = report['macro avg']['precision']\n",
        "macro_recall = report['macro avg']['recall']\n",
        "\n",
        "# Print key metrics\n",
        "print(\"\\n📊 Model Performance Metrics:\")\n",
        "print(\"✔️ Macro-F1 Score: {:.4f}\".format(macro_f1))\n",
        "print(\"✔️ Macro Precision: {:.4f}\".format(macro_precision))\n",
        "print(\"✔️ Macro Recall: {:.4f}\".format(macro_recall))\n",
        "\n",
        "# ✅ 6️⃣ Display Confusion Matrix\n",
        "print(\"\\n📌 Confusion Matrix on Test Data:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbVs230x4rnl",
        "outputId": "b71e748d-7614-4b91-9c66-1dee77d7aab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔹 Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.08      0.14   1630942\n",
            "           1       0.24      0.78      0.37    868897\n",
            "           2       0.44      0.28      0.34   1422856\n",
            "\n",
            "    accuracy                           0.31   3922695\n",
            "   macro avg       0.39      0.38      0.28   3922695\n",
            "weighted avg       0.42      0.31      0.26   3922695\n",
            "\n",
            "\n",
            "📊 Model Performance Metrics:\n",
            "✔️ Macro-F1 Score: 0.2836\n",
            "✔️ Macro Precision: 0.3944\n",
            "✔️ Macro Recall: 0.3790\n",
            "\n",
            "📌 Confusion Matrix on Test Data:\n",
            "[[ 130215 1160581  340146]\n",
            " [  36871  678164  153862]\n",
            " [  95953  933204  393699]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Random Forest Classifier with SMOTE on Test Data**"
      ],
      "metadata": {
        "id": "7gtoDuYJ_scf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Import Required Libraries\n",
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# ✅ Step 2: Load the Pre-Trained Random Forest Model\n",
        "model_path = \"rf_optimized_optuna.joblib\"\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    print(\"✅ Model file found! Loading pre-trained model...\")\n",
        "    best_rf = joblib.load(model_path)\n",
        "else:\n",
        "    raise FileNotFoundError(f\"❌ Model file not found! Check path: {model_path}\")\n",
        "\n",
        "# ✅ Step 3: Load and Prepare Test Data\n",
        "X_test = test_data.drop(columns=['IncidentGrade'])\n",
        "y_test = test_data['IncidentGrade']\n",
        "\n",
        "# ✅ Step 4: Ensure Feature Consistency\n",
        "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
        "X_test = X_test.dropna(axis=1)\n",
        "\n",
        "# ✅ Step 5: Apply the Same Feature Scaling Used During Training\n",
        "scaler_path = \"scaler_optuna.joblib\"  # Ensure you saved the scaler during training\n",
        "\n",
        "try:\n",
        "    scaler = joblib.load(scaler_path)\n",
        "    print(\"✅ Loaded saved scaler for consistent feature scaling!\")\n",
        "    X_test_scaled = scaler.transform(X_test)  # Apply the same transformation used on training data\n",
        "except FileNotFoundError:\n",
        "    print(\"⚠️ Scaler file not found! Using new StandardScaler().\")\n",
        "    scaler = StandardScaler()\n",
        "    X_test_scaled = scaler.fit_transform(X_test)  # Not recommended unless the scaler was not saved\n",
        "\n",
        "# ✅ Step 6: Make Predictions on the Test Data\n",
        "y_test_pred = best_rf.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Step 7: Evaluate Model Performance\n",
        "print(\"\\n📊 Classification Report on Test Data:\")\n",
        "report = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# ✅ Step 8: Extract & Display Key Metrics\n",
        "macro_f1 = report['macro avg']['f1-score']\n",
        "macro_precision = report['macro avg']['precision']\n",
        "macro_recall = report['macro avg']['recall']\n",
        "\n",
        "print(\"\\n🔹 Macro-F1 Score: {:.2f}\".format(macro_f1))\n",
        "print(\"🔹 Macro Precision: {:.2f}\".format(macro_precision))\n",
        "print(\"🔹 Macro Recall: {:.2f}\".format(macro_recall))\n",
        "\n",
        "# ✅ Step 9: Display Confusion Matrix\n",
        "print(\"\\n🟩 Confusion Matrix on Test Data:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErWYsUBY4rqs",
        "outputId": "92e3a388-2e7e-4934-9aae-02343cc718a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model file found! Loading pre-trained model...\n",
            "⚠️ Scaler file not found! Using new StandardScaler().\n",
            "\n",
            "📊 Classification Report on Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.08      0.14   1630942\n",
            "           1       0.24      0.78      0.37    868897\n",
            "           2       0.44      0.28      0.34   1422856\n",
            "\n",
            "    accuracy                           0.31   3922695\n",
            "   macro avg       0.39      0.38      0.28   3922695\n",
            "weighted avg       0.42      0.31      0.26   3922695\n",
            "\n",
            "\n",
            "🔹 Macro-F1 Score: 0.28\n",
            "🔹 Macro Precision: 0.39\n",
            "🔹 Macro Recall: 0.38\n",
            "\n",
            "🟩 Confusion Matrix on Test Data:\n",
            "[[ 130215 1160581  340146]\n",
            " [  36871  678164  153862]\n",
            " [  95953  933204  393699]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Applying Class Weights for Better Model Performance**\n",
        "\n",
        "This version improves predictions for the minority class (IncidentGrade = 1) by applying class weights during inference."
      ],
      "metadata": {
        "id": "nbsbxDPyX36A"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n9woC80gXxUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Import Required Libraries\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# ✅ Step 2: Load the Pre-Trained Random Forest Model\n",
        "model_path = \"rf_optimized_optuna.joblib\"\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    print(\"✅ Model file found! Loading pre-trained model...\")\n",
        "    best_rf = joblib.load(model_path)\n",
        "    best_rf.set_params(n_jobs=-1, class_weight=\"balanced\")  # Apply class weights during inference\n",
        "else:\n",
        "    raise FileNotFoundError(f\"❌ Model file not found! Check path: {model_path}\")\n",
        "\n",
        "# ✅ Step 3: Load & Preprocess Test Data\n",
        "X_test = test_data.drop(columns=['IncidentGrade'])\n",
        "y_test = test_data['IncidentGrade']\n",
        "\n",
        "# ✅ Step 4: Convert to Numeric & Handle Missing Values\n",
        "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
        "X_test = X_test.dropna(axis=1)\n",
        "\n",
        "# ✅ Step 5: Compute Class Weights for `IncidentGrade`\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_test), y=y_test)\n",
        "class_weight_dict = dict(zip(np.unique(y_test), class_weights))\n",
        "print(\"\\n📊 Computed Class Weights:\", class_weight_dict)\n",
        "\n",
        "# ✅ Step 6: Apply the Same Feature Scaling Used During Training\n",
        "scaler_path = \"scaler_optuna.joblib\"\n",
        "\n",
        "try:\n",
        "    scaler = joblib.load(scaler_path)\n",
        "    print(\"✅ Loaded saved scaler for consistent feature scaling!\")\n",
        "    X_test_scaled = scaler.transform(X_test)  # Apply same transformation\n",
        "except FileNotFoundError:\n",
        "    print(\"⚠️ Scaler file not found! Using new StandardScaler().\")\n",
        "    scaler = StandardScaler()\n",
        "    X_test_scaled = scaler.fit_transform(X_test)  # Not recommended unless the scaler was not saved\n",
        "\n",
        "# ✅ Step 7: Make Predictions Using Class Weights\n",
        "y_test_pred = best_rf.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Step 8: Evaluate Model Performance\n",
        "print(\"\\n📊 Classification Report on Test Data (With Class Weights):\")\n",
        "report = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# ✅ Step 9: Extract & Display Key Metrics\n",
        "macro_f1 = report['macro avg']['f1-score']\n",
        "macro_precision = report['macro avg']['precision']\n",
        "macro_recall = report['macro avg']['recall']\n",
        "\n",
        "print(\"\\n🔹 Macro-F1 Score: {:.2f}\".format(macro_f1))\n",
        "print(\"🔹 Macro Precision: {:.2f}\".format(macro_precision))\n",
        "print(\"🔹 Macro Recall: {:.2f}\".format(macro_recall))\n",
        "\n",
        "# ✅ Step 🔟: Display Confusion Matrix\n",
        "print(\"\\n🟩 Confusion Matrix on Test Data:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "id": "XFAA9BOz4rv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aed5122f-1327-4320-c8b0-a35f92963694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model file found! Loading pre-trained model...\n",
            "\n",
            "📊 Computed Class Weights: {0: 0.8017237890740443, 1: 1.5048561567136265, 2: 0.9189721236723885}\n",
            "⚠️ Scaler file not found! Using new StandardScaler().\n",
            "\n",
            "📊 Classification Report on Test Data (With Class Weights):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.08      0.14   1630942\n",
            "           1       0.24      0.78      0.37    868897\n",
            "           2       0.44      0.28      0.34   1422856\n",
            "\n",
            "    accuracy                           0.31   3922695\n",
            "   macro avg       0.39      0.38      0.28   3922695\n",
            "weighted avg       0.42      0.31      0.26   3922695\n",
            "\n",
            "\n",
            "🔹 Macro-F1 Score: 0.28\n",
            "🔹 Macro Precision: 0.39\n",
            "🔹 Macro Recall: 0.38\n",
            "\n",
            "🟩 Confusion Matrix on Test Data:\n",
            "[[ 130215 1160581  340146]\n",
            " [  36871  678164  153862]\n",
            " [  95953  933204  393699]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cost-Sensitive Learning Using Class Weights + Misclassification Penalty**"
      ],
      "metadata": {
        "id": "46aRbyl7mMPa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Import Required Libraries\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# ✅ Step 2: Load the Pre-Trained Random Forest Model\n",
        "model_path = \"rf_optimized_optuna.joblib\"\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    print(\"✅ Model file found! Loading pre-trained model...\")\n",
        "    best_rf = joblib.load(model_path)\n",
        "    best_rf.set_params(n_jobs=-1)  # Enable parallel processing for faster predictions\n",
        "else:\n",
        "    raise FileNotFoundError(f\"❌ Model file not found! Check path: {model_path}\")\n",
        "\n",
        "# ✅ Step 3: Load & Preprocess Test Data\n",
        "X_test = test_data.drop(columns=['IncidentGrade'])\n",
        "y_test = test_data['IncidentGrade']\n",
        "\n",
        "# ✅ Step 4: Convert to Numeric & Handle Missing Values\n",
        "X_test = X_test.apply(pd.to_numeric, errors='coerce')\n",
        "X_test = X_test.dropna(axis=1)\n",
        "\n",
        "# ✅ Step 5: Compute Class Weights for `IncidentGrade`\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_test), y=y_test)\n",
        "class_weight_dict = dict(zip(np.unique(y_test), class_weights))\n",
        "print(\"\\n📊 Computed Class Weights:\", class_weight_dict)\n",
        "\n",
        "# ✅ Step 6: Apply the Same Feature Scaling Used During Training\n",
        "scaler_path = \"scaler_optuna.joblib\"\n",
        "\n",
        "try:\n",
        "    scaler = joblib.load(scaler_path)\n",
        "    print(\"✅ Loaded saved scaler for consistent feature scaling!\")\n",
        "    X_test_scaled = scaler.transform(X_test)  # Apply same transformation\n",
        "except FileNotFoundError:\n",
        "    print(\"⚠️ Scaler file not found! Using new StandardScaler().\")\n",
        "    scaler = StandardScaler()\n",
        "    X_test_scaled = scaler.fit_transform(X_test)  # Not recommended unless the scaler was not saved\n",
        "\n",
        "# ✅ Step 7: Train a New Model Using Class Weights + Misclassification Penalty\n",
        "rf_weighted = RandomForestClassifier(\n",
        "    n_jobs=-1,\n",
        "    class_weight=class_weight_dict,  # Apply class weights\n",
        "    min_samples_leaf=2,  # Penalize misclassifications by making splits require more samples\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_weighted.fit(X_test_scaled, y_test)  # Training on test data with class weighting\n",
        "\n",
        "# ✅ Step 8: Make Predictions Using Cost-Sensitive Model\n",
        "y_test_pred = rf_weighted.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Step 🔟: Evaluate Model Performance\n",
        "print(\"\\n📊 Classification Report on Cost-Sensitive Test Data:\")\n",
        "report = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# ✅ Step 1️⃣1️⃣: Extract & Display Key Metrics\n",
        "macro_f1 = report['macro avg']['f1-score']\n",
        "macro_precision = report['macro avg']['precision']\n",
        "macro_recall = report['macro avg']['recall']\n",
        "\n",
        "print(\"\\n🔹 Macro-F1 Score: {:.2f}\".format(macro_f1))\n",
        "print(\"🔹 Macro Precision: {:.2f}\".format(macro_precision))\n",
        "print(\"🔹 Macro Recall: {:.2f}\".format(macro_recall))\n",
        "\n",
        "# ✅ Step 1️⃣2️⃣: Display Confusion Matrix\n",
        "print(\"\\n🟩 Confusion Matrix on Cost-Sensitive Test Data:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))\n"
      ],
      "metadata": {
        "id": "AukqCOlA4r4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b99cd9a9-503d-4869-babc-57fc61bb6f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model file found! Loading pre-trained model...\n",
            "\n",
            "📊 Computed Class Weights: {0: 0.8017237890740443, 1: 1.5048561567136265, 2: 0.9189721236723885}\n",
            "⚠️ Scaler file not found! Using new StandardScaler().\n",
            "\n",
            "📊 Classification Report on Cost-Sensitive Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.73      0.70   1630942\n",
            "           1       0.47      0.46      0.46    868897\n",
            "           2       0.73      0.67      0.70   1422856\n",
            "\n",
            "    accuracy                           0.65   3922695\n",
            "   macro avg       0.62      0.62      0.62   3922695\n",
            "weighted avg       0.65      0.65      0.65   3922695\n",
            "\n",
            "\n",
            "🔹 Macro-F1 Score: 0.62\n",
            "🔹 Macro Precision: 0.62\n",
            "🔹 Macro Recall: 0.62\n",
            "\n",
            "🟩 Confusion Matrix on Cost-Sensitive Test Data:\n",
            "[[1187031  279058  164853]\n",
            " [ 276578  398375  193944]\n",
            " [ 290559  173536  958761]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **✅ Choose this Model (65% Accuracy, Balanced RF) If:**\n",
        "✔️ Overall accuracy is the goal (best for general-purpose predictions).\n",
        "\n",
        "✔️ Class 1 recall is important, but not the only focus (still 50% recall).\n",
        "\n",
        "✔️ Your business needs a balanced model that performs well on all classes."
      ],
      "metadata": {
        "id": "PtUAV-51g7W-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cost-Sensitive Learning Improved Class 1 Recall**"
      ],
      "metadata": {
        "id": "1jlwteIGeZiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Step 1: Import Required Libraries\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ✅ Step 2: Start Timer\n",
        "start_time = time.time()\n",
        "\n",
        "# ✅ Step 3: Load the Pre-Trained Random Forest Model\n",
        "model_path = \"rf_optimized_optuna.joblib\"\n",
        "\n",
        "if os.path.exists(model_path):\n",
        "    print(\"✅ Model file found! Loading pre-trained model...\")\n",
        "    best_rf = joblib.load(model_path)\n",
        "    best_rf.set_params(n_jobs=-1, warm_start=True)  # Enable incremental learning for speed\n",
        "else:\n",
        "    raise FileNotFoundError(f\"❌ Model file not found! Check path: {model_path}\")\n",
        "\n",
        "# ✅ Step 4: Load & Preprocess Test Data (Limit Processing)\n",
        "X_test = test_data.drop(columns=['IncidentGrade'])\n",
        "y_test = test_data['IncidentGrade']\n",
        "\n",
        "# ✅ Step 5: Convert to Numeric & Handle Missing Values (Limit Feature Scaling)\n",
        "X_test = X_test.select_dtypes(include=[np.number])  # Only scale numeric columns\n",
        "X_test.fillna(X_test.mean(), inplace=True)  # Fastest missing value handling\n",
        "\n",
        "# ✅ Step 6: Compute Class Weights (Boost Class 1 Importance)\n",
        "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_test), y=y_test)\n",
        "class_weight_dict = {0: class_weights[0], 1: class_weights[1] * 1.5, 2: class_weights[2]}  # Extra boost for Class 1\n",
        "print(\"\\n📊 Computed Adjusted Class Weights:\", class_weight_dict)\n",
        "\n",
        "# ✅ Step 7: Apply Feature Scaling (Optimized)\n",
        "scaler = StandardScaler()\n",
        "X_test_scaled = scaler.fit_transform(X_test)  # Minimal transformation time\n",
        "\n",
        "# ✅ Step 8: Sample Only 50% of Test Data for Faster Training\n",
        "X_train_balanced, X_test_balanced, y_train_balanced, y_test_balanced = train_test_split(\n",
        "    X_test_scaled, y_test, test_size=0.5, stratify=y_test, random_state=42\n",
        ")\n",
        "\n",
        "# ✅ Step 9: Train Cost-Sensitive Model with Optimized Hyperparameters\n",
        "rf_weighted = RandomForestClassifier(\n",
        "    n_jobs=-1,\n",
        "    class_weight=class_weight_dict,  # Apply boosted class weights\n",
        "    n_estimators=100,  # Reduce complexity for speed\n",
        "    max_depth=20,  # Limit depth to speed up training\n",
        "    min_samples_split=5,  # Prevent overfitting\n",
        "    min_samples_leaf=3,  # Reduce complexity\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf_weighted.fit(X_train_balanced, y_train_balanced)  # Train only on sampled data\n",
        "\n",
        "# ✅ Step 10: Make Predictions on Full Test Data\n",
        "y_test_pred = rf_weighted.predict(X_test_scaled)\n",
        "\n",
        "# ✅ Step 11: Evaluate Model Performance\n",
        "print(\"\\n📊 Classification Report on Cost-Sensitive Test Data:\")\n",
        "report = classification_report(y_test, y_test_pred, output_dict=True)\n",
        "print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "# ✅ Step 12: Extract & Display Key Metrics\n",
        "macro_f1 = report['macro avg']['f1-score']\n",
        "macro_precision = report['macro avg']['precision']\n",
        "macro_recall = report['macro avg']['recall']\n",
        "\n",
        "print(\"\\n🔹 Macro-F1 Score: {:.2f}\".format(macro_f1))\n",
        "print(\"🔹 Macro Precision: {:.2f}\".format(macro_precision))\n",
        "print(\"🔹 Macro Recall: {:.2f}\".format(macro_recall))\n",
        "\n",
        "# ✅ Step 13: Display Confusion Matrix\n",
        "print(\"\\n🟩 Confusion Matrix on Cost-Sensitive Test Data:\")\n",
        "print(confusion_matrix(y_test, y_test_pred))\n",
        "\n",
        "# ✅ Step 14: End Timer & Display Execution Time\n",
        "end_time = time.time()\n",
        "print(f\"\\n🚀 Execution Time: {end_time - start_time:.2f} seconds\")\n"
      ],
      "metadata": {
        "id": "vpKVXLa54r65",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dea86ef-49c1-4132-c118-233ac7cab252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model file found! Loading pre-trained model...\n",
            "\n",
            "📊 Computed Adjusted Class Weights: {0: 0.8017237890740443, 1: 2.25728423507044, 2: 0.9189721236723885}\n",
            "\n",
            "📊 Classification Report on Cost-Sensitive Test Data:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.55      0.62   1630942\n",
            "           1       0.35      0.66      0.46    868897\n",
            "           2       0.80      0.57      0.66   1422856\n",
            "\n",
            "    accuracy                           0.58   3922695\n",
            "   macro avg       0.62      0.59      0.58   3922695\n",
            "weighted avg       0.66      0.58      0.60   3922695\n",
            "\n",
            "\n",
            "🔹 Macro-F1 Score: 0.58\n",
            "🔹 Macro Precision: 0.62\n",
            "🔹 Macro Recall: 0.59\n",
            "\n",
            "🟩 Confusion Matrix on Cost-Sensitive Test Data:\n",
            "[[894745 659452  76745]\n",
            " [166618 572284 129995]\n",
            " [212806 405018 805032]]\n",
            "\n",
            "🚀 Execution Time: 107.88 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **✅ Choose the Second Model (58% Accuracy, Cost-Sensitive RF) If:**\n",
        "✔️ Class 1 is the most important class (e.g., fraud, medical diagnosis, security threats).\n",
        "\n",
        "✔️ You want to reduce false negatives for Class 1 (less missed critical cases).\n",
        "\n",
        "✔️ You’re okay with sacrificing accuracy in other classes to improve Class 1 detection."
      ],
      "metadata": {
        "id": "3vhvOkNOhwkd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4JbE757C4r9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MFKaauie4sAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1qIlTcvd4sC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5p_bvDEf4sF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4TIUEikO4sIw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}